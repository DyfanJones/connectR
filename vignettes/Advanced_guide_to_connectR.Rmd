---
title: "Advanced Guide to connectR"
author: "Dyfan Jones"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

##Lazy methods to send queries to Database

First method would be to send SQL query directly to the database. The second method would to use dplyr's functions to create the SQL query. Both methods allow R to manipulate data on the database with out actually pulling the data into R and filling up R's memory. 

Firstly lets make a connection to the database.

```{r packages, results="hide", warning= FALSE, message= F}
library(tidyverse)
library(connectR)

src_connectR("PostgreSQL35W")->post
```

- **method 1:**
```{r, fig.show='hold'}
db_send_query(post,"create table kaggle_test as
                        (Select
                        a.name,
                        a.style,
                        a.abv,
                        b.brewery_name,
                        b.city
                        from kaggle_beers a
                        inner join kaggle_breweries b
                        on a.brewery_id = b.brewery_id) with no data;")

db_send_query(post,"insert into kaggle_test
                        Select
                        a.name,
                        a.style,
                        a.abv,
                        b.brewery_name,
                        b.city
                        from kaggle_beers a
                        inner join kaggle_breweries b
                        on a.brewery_id = b.brewery_id
                        where b.city = 'San Francisco';")

#Let's view the data.

tbl(post,"kaggle_test") 
```

```{r, fig.show='hold'}
db_send_query(post,"drop table kaggle_test")
```

- **Method 2:**
```{r, fig.show='hold'}
tbl(post,"kaggle_beers")->beers
tbl(post,"kaggle_breweries")->breweries

inner_join(beers %>% 
             select(name,style,abv,brewery_id),
           breweries %>% select(brewery_id,brewery_name,city) %>%
             filter(city=="San Francisco"),
           by=c("brewery_id","brewery_id")) %>% compute(name = "kaggle_test",temporary=F)

#Let's view the data.

tbl(post,"kaggle_test") 
```

```{r, fig.show='hold'}
db_drop_table(post$con,"kaggle_test")
```

## Deeper look into dplyr
We know the SQL query that was sent to the database in method 1, but what was the SQL query generated by dplyr? To answer this we can use the `show_query` function.

```{r, fig.show='hold'}
inner_join(beers %>% 
             select(name,style,abv,brewery_id),
           breweries %>% select(brewery_id,brewery_name,city) %>%
             filter(city=="San Francisco"),
           by=c("brewery_id","brewery_id")) %>% show_query
```

Both methods send SQL queries to the database. As suspected the SQL queries are very similar, dplyr subsets each table before doing the join. However this will be down to how the R dplyr code has been constructed. We can alert the code so that the select, and filter functions are out side the inner_join then dplyr will generate different SQL.
```{r, fig.show='hold'}
inner_join(beers,breweries,
           by=c("brewery_id","brewery_id")) %>%
  select(name,style,abv,brewery_name,city) %>% 
  filter(city=="San Francisco")%>% show_query
```
As long as you write working R dplyr code, dplyr is rebust enough to generate the SQL variant. This makes R dplyr a really useful tool kit within the R family.